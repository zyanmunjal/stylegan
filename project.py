# -*- coding: utf-8 -*-
"""PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19I3-rhbD5kCF5Gx8AHw5qm1OR3ej99qJ
"""

!nvidia-smi

!pip install --upgrade pip
!pip install click requests tqdm pyspng ninja imageio-ffmpeg --quiet
# Install torch and torchvision without torchaudio
!pip install torch==2.0.1 torchvision==0.15.2

!pip install numpy==1.26.0
!pip install --upgrade --no-deps numpy==1.26.0

# Clean any previous clones
!rm -rf stylegan2-ada-pytorch

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git
# %cd stylegan2-ada-pytorch

from google.colab import drive
drive.mount('/content/drive')

# Dataset location
dataset_raw_path = '/content/drive/MyDrive/finalDataset'

import os
from PIL import Image
import matplotlib.pyplot as plt

# Check if dataset exists
if os.path.exists(dataset_raw_path):
    print(f"Dataset found at: {dataset_raw_path}")
else:
    raise Exception("Dataset not found! Please check your Google Drive path.")

# Get list of images
image_files = [f for f in os.listdir(dataset_raw_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

# Display some images
num_images_to_show = 5  # You can change this number
plt.figure(figsize=(15, 5))

for i in range(min(num_images_to_show, len(image_files))):
    img_path = os.path.join(dataset_raw_path, image_files[i])
    img = Image.open(img_path)

    plt.subplot(1, num_images_to_show, i + 1)
    plt.imshow(img)
    plt.axis('off')
    plt.title(f"Image {i+1}")

plt.show()

# Define output path for TFRecords
dataset_tfrecords_path = '/content/drive/MyDrive/finalDataset-tfrecords'

# Convert if not already converted
if not os.path.exists(dataset_tfrecords_path):
    print("Converting images to TFRecords format...")
    !python dataset_tool.py --source={dataset_raw_path} --dest={dataset_tfrecords_path}
else:
    print("TFRecords dataset already exists. Skipping conversion.")

!mkdir -p /content/pretrained_models

!wget -c -O /content/pretrained_models/ffhq.pkl https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl

output_dir = '/content/drive/MyDrive/stylegan2-ada-training-runs'
resume_model = '/content/pretrained_models/ffhq.pkl'
gpus = 1  # Number of GPUs
batch_size = 8  # Batch size (small for Colab Free)
gamma_value = 10  # R1 regularization weight
kimg = 1  # How much to train (in thousands of images, keep low for Colab Free)
snapshot_interval = 1  # Save snapshot every X ticks
metrics_to_calculate = 'fid50k_full'  # Evaluate FID during training

!python train.py \
  --outdir={output_dir} \
  --data={dataset_tfrecords_path} \
  --gpus={gpus} \
  --batch={batch_size} \
  --gamma={gamma_value} \
  --snap=10 \
  --resume={resume_model} \
  --metrics=none \
  --kimg=1 \
  --cfg=stylegan2 \
  --aug=noaug  # Disable augmentations to avoid grid sampler issues

import os

output_dir = '/content/drive/MyDrive/stylegan2-ada-training-runs'
print("Checking files in the output directory:")
print(os.listdir(output_dir))

import os
import glob

# 1. Define paths
output_dir = '/content/drive/MyDrive/stylegan2-ada-training-runs/00000-finalDataset-tfrecords-stylegan2-gamma10-kimg1-batch8-noaug-resumecustom'
dataset_path = '/content/drive/MyDrive/finalDataset'  # Path to your real images (500 images)
snapshot_files = sorted(glob.glob(output_dir + '/network-snapshot-*.pkl'))

# 2. Find the latest model
if snapshot_files:
    latest_snapshot = snapshot_files[-1]
    print(f"✅ Latest network snapshot found: {latest_snapshot}")
else:
    raise Exception("❌ No model snapshot found. Please check your training output directory.")

# 3. Calculate FID using the generate_fid command
fid_output_dir = '/content/drive/MyDrive/fid-results'

os.makedirs(fid_output_dir, exist_ok=True)

# 4. Run StyleGAN2-ADA's calc_metrics.py to compute FID
!python calc_metrics.py \
  --metrics=fid50k_full \
  --network={latest_snapshot} \
  --data={dataset_path} \
  --mirror=1 \
  --gpus=1

# Install dependencies if needed
!pip install click requests tqdm pyspng ninja imageio-ffmpeg --quiet

# Path to your trained model
network_pkl = latest_snapshot  # <-- you already got latest_snapshot above

# Output folder where generated images will be saved
outdir = '/content/drive/MyDrive/generated-images'
os.makedirs(outdir, exist_ok=True)

# Latent vector input (change this part to your input encoding mechanism)
# This example assumes you already have the latent vector for the input image.
# You should replace this part with actual logic to encode the input image.

# If you already have the latent vector of the input image, you can set it here.
# Example: latent_vector = encode_input_image(input_image_path)

# Generate fake images by perturbing the latent vector for variations
!python generate.py \
  --outdir={outdir} \
  --trunc=0.7 \
  --seeds=0-49 \
  --network={network_pkl}

!pip install click requests tqdm pyspng ninja imageio-ffmpeg scipy pillow --quiet

import os
import numpy as np
import torch
import dnnlib
import legacy
from PIL import Image
from google.colab import files

uploaded_images_dir = '/content/uploaded_images'
os.makedirs(uploaded_images_dir, exist_ok=True)

projected_dir = '/content/projected_latents'
os.makedirs(projected_dir, exist_ok=True)

generated_images_dir = '/content/drive/MyDrive/generated_variations'
os.makedirs(generated_images_dir, exist_ok=True)

from google.colab import files
import os

upload_dir = "/content/uploaded_images"
os.makedirs(upload_dir, exist_ok=True)

uploaded = files.upload()
for filename in uploaded.keys():
    new_path = os.path.join(upload_dir, filename)
    os.rename(filename, new_path)
    print(f"✅ Uploaded: {new_path}")

!wget -q https://raw.githubusercontent.com/NVlabs/stylegan2-ada-pytorch/main/projector.py

uploaded_files = os.listdir("/content/uploaded_images")
print(uploaded_files)

input_image_path = "/content/uploaded_images/Screenshot 2025-04-29 095931 (3).png"
projected_dir = "/content/projected_latents"
os.makedirs(projected_dir, exist_ok=True)

projected_latent_path = os.path.join(projected_dir, 'projected_w.npz')
network_pkl = latest_snapshot  # already loaded above

!python projector.py \
    --outdir="{projected_dir}" \
    --target="{input_image_path}" \
    --network="{latest_snapshot}" \
    --save-video=0

